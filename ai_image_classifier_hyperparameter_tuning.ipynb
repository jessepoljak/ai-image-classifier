{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from keras.models import Sequential\n",
    "from tensorflow.keras import layers\n",
    "from keras.optimizers import Adam, SGD, RMSprop, Adadelta, Adagrad, Adamax, Nadam, Ftrl\n",
    "from keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from scikeras.wrappers import KerasClassifier\n",
    "from math import floor\n",
    "from sklearn.metrics import make_scorer, accuracy_score\n",
    "from bayes_opt import BayesianOptimization\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from keras.layers import LeakyReLU\n",
    "LeakyReLU = LeakyReLU(alpha=0.1)\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "pd.set_option(\"display.max_columns\", None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Make scorer accuracy\n",
    "score_acc = make_scorer(accuracy_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Import the pkl file.\n",
    "with open('ai_image_classifier_small_img.pkl', 'rb') as file:\n",
    "    recalled_imgs = pickle.load(file)\n",
    "\n",
    "type(recalled_imgs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set train, test variables.\n",
    "X_train = recalled_imgs['X_train']\n",
    "X_test = recalled_imgs['X_test']\n",
    "y_train = recalled_imgs['y_train']\n",
    "y_test = recalled_imgs['y_test']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert values to numpy arrays\n",
    "X_train_aug_np = np.array(X_train)\n",
    "X_test_np = np.array(X_test)\n",
    "y_train_aug_np = np.array(y_train) \n",
    "y_test_np = np.array(y_test)\n",
    "\n",
    "# Load and preprocess your CMU Face Images dataset (Ensure each image is labeled as \"with sunglasses\" or \"without sunglasses\")\n",
    "# The following code assumes that you have already loaded and preprocessed your dataset into 'X' and 'y' (features and labels).\n",
    "\n",
    "# Split the training dataset into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X_train_aug_np, y_train_aug_np, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create function\n",
    "def nn_cl_bo(neurons, activation, optimizer, lr,  batch_size, epochs ):\n",
    "    optimizerL = ['SGD', 'Adam', 'RMSprop', 'Adadelta', 'Adagrad', 'Adamax', 'Nadam', 'Ftrl']\n",
    "    optimizerD= {'Adam':Adam(learning_rate=lr), 'SGD':SGD(learning_rate=lr),\n",
    "                 'RMSprop':RMSprop(learning_rate=lr), 'Adadelta':Adadelta(learning_rate=lr),\n",
    "                 'Adagrad':Adagrad(learning_rate=lr), 'Adamax':Adamax(learning_rate=lr),\n",
    "                 'Nadam':Nadam(learning_rate=lr), 'Ftrl':Ftrl(learning_rate=lr)}\n",
    "    activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "                   'elu', 'exponential', LeakyReLU,'relu']\n",
    "    neurons = round(neurons)\n",
    "    activation = activationL[round(activation)]\n",
    "    batch_size = round(batch_size)\n",
    "    epochs = round(epochs)\n",
    "    def nn_cl_fun():\n",
    "        opt = optimizerD[optimizerL[round(optimizer)]]\n",
    "        nn = Sequential()\n",
    "        nn.add(layers.Conv2D(neurons, (3, 3), activation=activation, input_shape=(64, 64, 3)))\n",
    "        nn.add(layers.MaxPooling2D((2, 2)))\n",
    "        nn.add(layers.Flatten())\n",
    "        nn.add(layers.Dense(1, activation='sigmoid'))\n",
    "        nn.compile(loss='binary_crossentropy', optimizer=opt, metrics=['accuracy'])\n",
    "        return nn\n",
    "    es = EarlyStopping(monitor='accuracy', mode='max', verbose=0, patience=20)\n",
    "    nn = KerasClassifier(build_fn=nn_cl_fun, epochs=epochs, batch_size=batch_size,\n",
    "                         verbose=0)\n",
    "    kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=123)\n",
    "    score = cross_val_score(nn, X_train, y_train, scoring=score_acc, cv=kfold, fit_params={'callbacks':[es]})\n",
    "    score=np.nan_to_num(score)\n",
    "    score=score.mean()\n",
    "    return score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "|   iter    |  target   | activa... | batch_... |  epochs   |    lr     |  neurons  | optimizer |\n",
      "-------------------------------------------------------------------------------------------------\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020D298039A0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "| \u001b[39m1        \u001b[39m | \u001b[39m0.1529   \u001b[39m | \u001b[39m5.51     \u001b[39m | \u001b[39m335.3    \u001b[39m | \u001b[39m54.88    \u001b[39m | \u001b[39m0.7716   \u001b[39m | \u001b[39m36.58    \u001b[39m | \u001b[39m1.044    \u001b[39m |\n",
      "WARNING:tensorflow:5 out of the last 14 calls to <function TensorFlowTrainer.make_predict_function.<locals>.one_step_on_data_distributed at 0x0000020D318AF5B0> triggered tf.function retracing. Tracing is expensive and the excessive number of tracings could be due to (1) creating @tf.function repeatedly in a loop, (2) passing tensors with different shapes, (3) passing Python objects instead of tensors. For (1), please define your @tf.function outside of the loop. For (2), @tf.function has reduce_retracing=True option that can avoid unnecessary retracing. For (3), please refer to https://www.tensorflow.org/guide/function#controlling_retracing and https://www.tensorflow.org/api_docs/python/tf/function for  more details.\n",
      "| \u001b[39m2        \u001b[39m | \u001b[39m0.09844  \u001b[39m | \u001b[39m0.2023   \u001b[39m | \u001b[39m536.2    \u001b[39m | \u001b[39m39.09    \u001b[39m | \u001b[39m0.3443   \u001b[39m | \u001b[39m99.16    \u001b[39m | \u001b[39m1.664    \u001b[39m |\n",
      "| \u001b[39m3        \u001b[39m | \u001b[39m0.1239   \u001b[39m | \u001b[39m0.7307   \u001b[39m | \u001b[39m735.7    \u001b[39m | \u001b[39m69.7     \u001b[39m | \u001b[39m0.2815   \u001b[39m | \u001b[39m51.96    \u001b[39m | \u001b[39m0.8286   \u001b[39m |\n",
      "| \u001b[39m4        \u001b[39m | \u001b[39m0.1178   \u001b[39m | \u001b[39m0.6656   \u001b[39m | \u001b[39m920.6    \u001b[39m | \u001b[39m83.52    \u001b[39m | \u001b[39m0.8422   \u001b[39m | \u001b[39m83.37    \u001b[39m | \u001b[39m6.937    \u001b[39m |\n",
      "| \u001b[39m5        \u001b[39m | \u001b[39m0.1042   \u001b[39m | \u001b[39m5.195    \u001b[39m | \u001b[39m851.0    \u001b[39m | \u001b[39m53.71    \u001b[39m | \u001b[39m0.03717  \u001b[39m | \u001b[39m50.87    \u001b[39m | \u001b[39m0.7373   \u001b[39m |\n",
      "| \u001b[39m6        \u001b[39m | \u001b[39m0.135    \u001b[39m | \u001b[39m7.355    \u001b[39m | \u001b[39m758.2    \u001b[39m | \u001b[39m65.22    \u001b[39m | \u001b[39m0.2815   \u001b[39m | \u001b[39m99.86    \u001b[39m | \u001b[39m0.9663   \u001b[39m |\n",
      "| \u001b[39m7        \u001b[39m | \u001b[39m0.1463   \u001b[39m | \u001b[39m5.539    \u001b[39m | \u001b[39m588.0    \u001b[39m | \u001b[39m52.4     \u001b[39m | \u001b[39m0.7306   \u001b[39m | \u001b[39m39.05    \u001b[39m | \u001b[39m2.804    \u001b[39m |\n",
      "| \u001b[39m8        \u001b[39m | \u001b[39m0.1223   \u001b[39m | \u001b[39m2.871    \u001b[39m | \u001b[39m957.8    \u001b[39m | \u001b[39m93.5     \u001b[39m | \u001b[39m0.8157   \u001b[39m | \u001b[39m13.07    \u001b[39m | \u001b[39m6.604    \u001b[39m |\n",
      "| \u001b[39m9        \u001b[39m | \u001b[39m0.09844  \u001b[39m | \u001b[39m8.554    \u001b[39m | \u001b[39m845.3    \u001b[39m | \u001b[39m58.5     \u001b[39m | \u001b[39m0.9671   \u001b[39m | \u001b[39m47.53    \u001b[39m | \u001b[39m2.232    \u001b[39m |\n",
      "| \u001b[39m10       \u001b[39m | \u001b[39m0.09844  \u001b[39m | \u001b[39m0.148    \u001b[39m | \u001b[39m230.5    \u001b[39m | \u001b[39m24.25    \u001b[39m | \u001b[39m0.1367   \u001b[39m | \u001b[39m13.0     \u001b[39m | \u001b[39m1.585    \u001b[39m |\n",
      "| \u001b[39m11       \u001b[39m | \u001b[39m0.1273   \u001b[39m | \u001b[39m4.895    \u001b[39m | \u001b[39m342.9    \u001b[39m | \u001b[39m34.35    \u001b[39m | \u001b[39m0.1581   \u001b[39m | \u001b[39m71.47    \u001b[39m | \u001b[39m3.283    \u001b[39m |\n",
      "| \u001b[39m12       \u001b[39m | \u001b[39m0.1227   \u001b[39m | \u001b[39m6.914    \u001b[39m | \u001b[39m735.1    \u001b[39m | \u001b[39m55.3     \u001b[39m | \u001b[39m0.5993   \u001b[39m | \u001b[39m51.55    \u001b[39m | \u001b[39m6.743    \u001b[39m |\n",
      "| \u001b[39m13       \u001b[39m | \u001b[39m0.1246   \u001b[39m | \u001b[39m1.33     \u001b[39m | \u001b[39m925.5    \u001b[39m | \u001b[39m59.83    \u001b[39m | \u001b[39m0.5966   \u001b[39m | \u001b[39m71.62    \u001b[39m | \u001b[39m1.242    \u001b[39m |\n",
      "| \u001b[39m14       \u001b[39m | \u001b[39m0.1262   \u001b[39m | \u001b[39m7.782    \u001b[39m | \u001b[39m585.7    \u001b[39m | \u001b[39m25.55    \u001b[39m | \u001b[39m0.3711   \u001b[39m | \u001b[39m42.54    \u001b[39m | \u001b[39m3.304    \u001b[39m |\n",
      "| \u001b[39m15       \u001b[39m | \u001b[39m0.1449   \u001b[39m | \u001b[39m1.615    \u001b[39m | \u001b[39m340.2    \u001b[39m | \u001b[39m95.93    \u001b[39m | \u001b[39m0.6591   \u001b[39m | \u001b[39m22.15    \u001b[39m | \u001b[39m6.495    \u001b[39m |\n",
      "| \u001b[39m16       \u001b[39m | \u001b[39m0.1128   \u001b[39m | \u001b[39m7.576    \u001b[39m | \u001b[39m242.2    \u001b[39m | \u001b[39m36.29    \u001b[39m | \u001b[39m0.8738   \u001b[39m | \u001b[39m70.65    \u001b[39m | \u001b[39m2.081    \u001b[39m |\n",
      "| \u001b[39m17       \u001b[39m | \u001b[39m0.09844  \u001b[39m | \u001b[39m6.61     \u001b[39m | \u001b[39m694.7    \u001b[39m | \u001b[39m36.84    \u001b[39m | \u001b[39m0.804    \u001b[39m | \u001b[39m15.32    \u001b[39m | \u001b[39m2.158    \u001b[39m |\n",
      "| \u001b[39m18       \u001b[39m | \u001b[39m0.1209   \u001b[39m | \u001b[39m1.866    \u001b[39m | \u001b[39m977.8    \u001b[39m | \u001b[39m92.75    \u001b[39m | \u001b[39m0.6797   \u001b[39m | \u001b[39m20.37    \u001b[39m | \u001b[39m6.706    \u001b[39m |\n",
      "| \u001b[39m19       \u001b[39m | \u001b[39m0.1417   \u001b[39m | \u001b[39m0.8254   \u001b[39m | \u001b[39m703.8    \u001b[39m | \u001b[39m92.23    \u001b[39m | \u001b[39m0.3464   \u001b[39m | \u001b[39m68.75    \u001b[39m | \u001b[39m6.476    \u001b[39m |\n",
      "| \u001b[39m20       \u001b[39m | \u001b[39m0.1361   \u001b[39m | \u001b[39m3.366    \u001b[39m | \u001b[39m817.1    \u001b[39m | \u001b[39m91.69    \u001b[39m | \u001b[39m0.624    \u001b[39m | \u001b[39m23.6     \u001b[39m | \u001b[39m2.624    \u001b[39m |\n",
      "| \u001b[39m21       \u001b[39m | \u001b[39m0.1424   \u001b[39m | \u001b[39m5.723    \u001b[39m | \u001b[39m567.3    \u001b[39m | \u001b[39m62.58    \u001b[39m | \u001b[39m0.3588   \u001b[39m | \u001b[39m69.39    \u001b[39m | \u001b[39m3.336    \u001b[39m |\n",
      "| \u001b[39m22       \u001b[39m | \u001b[39m0.1147   \u001b[39m | \u001b[39m4.091    \u001b[39m | \u001b[39m299.8    \u001b[39m | \u001b[39m53.0     \u001b[39m | \u001b[39m0.2804   \u001b[39m | \u001b[39m41.21    \u001b[39m | \u001b[39m6.821    \u001b[39m |\n",
      "| \u001b[39m23       \u001b[39m | \u001b[39m0.1068   \u001b[39m | \u001b[39m1.94     \u001b[39m | \u001b[39m746.3    \u001b[39m | \u001b[39m22.54    \u001b[39m | \u001b[39m0.837    \u001b[39m | \u001b[39m73.15    \u001b[39m | \u001b[39m6.762    \u001b[39m |\n",
      "| \u001b[39m24       \u001b[39m | \u001b[39m0.1067   \u001b[39m | \u001b[39m5.326    \u001b[39m | \u001b[39m373.9    \u001b[39m | \u001b[39m77.54    \u001b[39m | \u001b[39m0.04056  \u001b[39m | \u001b[39m47.68    \u001b[39m | \u001b[39m1.969    \u001b[39m |\n",
      "| \u001b[39m25       \u001b[39m | \u001b[39m0.1479   \u001b[39m | \u001b[39m0.9562   \u001b[39m | \u001b[39m541.1    \u001b[39m | \u001b[39m87.25    \u001b[39m | \u001b[39m0.1193   \u001b[39m | \u001b[39m98.8     \u001b[39m | \u001b[39m1.633    \u001b[39m |\n",
      "| \u001b[39m26       \u001b[39m | \u001b[39m0.1472   \u001b[39m | \u001b[39m6.911    \u001b[39m | \u001b[39m334.4    \u001b[39m | \u001b[39m73.42    \u001b[39m | \u001b[39m0.02993  \u001b[39m | \u001b[39m20.27    \u001b[39m | \u001b[39m2.135    \u001b[39m |\n",
      "| \u001b[39m27       \u001b[39m | \u001b[39m0.1195   \u001b[39m | \u001b[39m1.307    \u001b[39m | \u001b[39m341.3    \u001b[39m | \u001b[39m44.13    \u001b[39m | \u001b[39m0.5617   \u001b[39m | \u001b[39m22.14    \u001b[39m | \u001b[39m0.2422   \u001b[39m |\n",
      "| \u001b[39m28       \u001b[39m | \u001b[39m0.1126   \u001b[39m | \u001b[39m7.852    \u001b[39m | \u001b[39m331.9    \u001b[39m | \u001b[39m77.26    \u001b[39m | \u001b[39m0.4171   \u001b[39m | \u001b[39m46.16    \u001b[39m | \u001b[39m0.8882   \u001b[39m |\n",
      "| \u001b[35m29       \u001b[39m | \u001b[35m0.1535   \u001b[39m | \u001b[35m8.24     \u001b[39m | \u001b[35m332.4    \u001b[39m | \u001b[35m58.64    \u001b[39m | \u001b[35m0.2701   \u001b[39m | \u001b[35m25.5     \u001b[39m | \u001b[35m4.714    \u001b[39m |\n",
      "=================================================================================================\n"
     ]
    }
   ],
   "source": [
    "# Set paramaters\n",
    "params_nn ={\n",
    "    'neurons': (10, 100),\n",
    "    'activation':(0, 9),\n",
    "    'optimizer':(0, 7),\n",
    "    'lr':(0.01, 1),\n",
    "    'batch_size':(200, 1000),\n",
    "    'epochs':(20, 100)\n",
    "}\n",
    "# Run Bayesian Optimization\n",
    "nn_bo = BayesianOptimization(nn_cl_bo, params_nn, random_state=111)\n",
    "nn_bo.maximize(init_points=25, n_iter=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'activation': <LeakyReLU name=leaky_re_lu_4, built=True>,\n",
       " 'batch_size': 332.36703829540227,\n",
       " 'epochs': 58.6363629536105,\n",
       " 'lr': 0.27010478764250984,\n",
       " 'neurons': 25.501069518528467,\n",
       " 'optimizer': 4.713791267287378}"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "params_nn_ = nn_bo.max['params']\n",
    "activationL = ['relu', 'sigmoid', 'softplus', 'softsign', 'tanh', 'selu',\n",
    "               'elu', 'exponential', LeakyReLU,'relu']\n",
    "params_nn_['activation'] = activationL[round(params_nn_['activation'])]\n",
    "params_nn_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
